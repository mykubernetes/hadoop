                            元数据安装
一准备工作
1.	创建hadoop用户
2.	配置免密登陆
3.  格式化数据盘（ext4）并在/etc/fstab文件增加 noatime  nodiratime参数以减少IO
    cat /etc/fstab
    /dev/sdb1    /mnt/data     ext4    defaults,noatime,nodiratime     0 0
4.	优化内核限制文件数和打开的进程数
    cat  /etc/security/limits.conf  |grep "^*"
    * soft    nofile    924511
    * sift    nproc     924511
    * hard    nproc     924511
    * hard    nofile    924511
5.	内核参数优化和关闭vm.swappiness=0 避免内存交换
6.  闭SWAP交换空间
7.  关闭内存交换
    cat /etc/sysctl.conf | grep -V "^#"
    net.core.netdev_max_backlog = 65536
    net.ipv4.ip_local_port_range = 10001 65535
    net.core.somaxconn = 32768
    net.ipv4.tcp_max_syn_backlog = 65536
    vm.swappiness= 0
 二、配置
日志目录：
  Hadoop-env.xml
export HADOOP_LOG_DIR=/data1/logs/hdfs
	zkEnv.sh 
ZOO_LOG_DIR=“/data1/logs/zookeeper”
	Hbase-env.sh 
export HBASE_LOG_DIR=/data1/logs/hbase

数据目录：
	hdfs-site.xml
<name>dfs.datanode.data.dir</name>
<value>/data2/data,/data3/data,……<value>

	hbase-site.xml
<name>hbase.zookeeper.property.dataDir</name>
     <value>/data1/hbase_data</value>

索引目录：
	zoo.cfg
datadir=/data2/index/zk_datastore
dataLogDir=/data2/index/zk_datastore_log
 
hdfs-site.xml
<name>dfs.journalnode.edits.dir</name>
     <value>/data2/index/journalnode</value>
 
其他目录：
	hbase-site.xml
     <name>hbase.tmp.dir</name>
     <value>/data1/other/hbase_tmp</value>
 
      <name>hbase.local.dir</name>
      <value>/data1/other/hbase_local</value>
 
	cour-site.xml
      <name>hadoop.tmp.dir</name>
      <value>/data1/other/hadoop_tmp</value>





Hadoop：配置文件所在目录为$HADOOP_HOME/etc/hadoop，需要配置的配置文件有hadoop-env.sh、hdfs-site.xml、core-site.xml、slaves。
1. hadoop-env.sh
	需要配置的参数：JAVA_HOME、HADOOP_HOME、HADOOP_HEAPSIZE，其中
JAVA_HOME、HADOOP_HOME分别为java和hadoop的安装目录，HEAPSIZE为分配给hadoop的内存大小，可根据节点内存大小进行调整，默认为8000, HADOOP_LOG_DIR为hdfs日志存放目录。
2. hdfs-site.xml
需要配置以下参数，其余参数采用默认值。
		<property>
            <name>dfs.namenode.rpc-address.oos-hbase.nn1</name>
       	  	<value>node01:8020</value>
        </property>
		说明：该参数为NameNode主节点
        <property>
            <name>dfs.namenode.rpc-address.oos-hbase.nn2</name>
             <value>node02:8020</value>
  		</property>
		说明：该参数为NameNode备节点
		<property>
            <name>dfs.namenode.shared.edits.dir</name>
              <value>qjournal://node01:8485;node02:8485;node03:8485/oos-hbase</value>
        </property>
		说明：该参数为JournalNode部署的节点
		<property>
                <name>dfs.ha.fencing.ssh.private-key-files</name>
                <value>/root/.ssh/id_rsa</value>
        </property>
		说明：该参数为id_rsa所在的目录
		<property>
                <name>dfs.journalnode.edits.dir</name>
                <value>/mnt/hhzData/journal/data</value>
        </property>
		说明：该参数为JournalNode存储数据的目录
		<property>
          		<name>dfs.datanode.data.dir</name>
            	<value>/mnt/hhzData/hdfs/data</value>
        </property>
		说明：该参数为DataNode存储数据的目录
		<property>
                <name>hbase.zookeeper.quorum</name>
                <value>node01:2181,node02:2181,node03:2181</value>
        </property>
		说明：该参数为zk所在的节点
3. core-site.xml
需要配置以下参数，其余参数采用默认值。
	<property>
         <name>ha.zookeeper.quorum</name>
         <value> node01:2181,node02:2181,node03:2181</value>
    </property>
	说明：该参数为zk节点
    <property>
         <name>hadoop.tmp.dir</name>
         <value>/var/hadoop/datastore</value>
     </property>
	说明：该参数为hadoop临时目录
4. slaves
配置所有的DataNode节点，每个节点一行，格式如下所示：
		node01
		node02
		node03
HBase：配置文件所在目录为$HBASE_HOME/conf，需要配置的配置文件有
	hbase-env.sh、hbase-site.xml、backup-masters、regionservers、metaRegion、	hdfs-site.xml。
1. hbase-env.sh
	需要配置以下参数，其余参数采用默认值。
	HBASE_HOME、HADOOP_HOME 、JAVA_HOME、HBASE_HEAPSIZE、LD_LIBRARY_PATH，其中HBASE_HOME、HADOOP_HOME 、JAVA_HOME分别为hbase、hadoop、java的安装目录。
	HBASE_HEAPSIZE为hbase的内存大小，可根据节点内存大小进行调整，默认为8000。	LD_LIBRARY_PATH为lzo的安装目录，HBASE_LOG_DIR为hbase的日志目录。
./conf/hbase-env.sh:export HBASE_LOG_DIR=/data1/logs/hbase

2. hbase-site.xml
	需要配置以下参数，其余参数采用默认值。
		<property>
            	<name>hbase.master</name>
            	<value>node01:60000</value>
 		</property>
		说明：该参数为hbase的主节点
		 <property>
                <name>hbase.zookeeper.quorum</name>
                <value>node01:2181,node02:2181,node03:2181</value>
		 </property>
		说明：该参数为zk的安装节点
 		<property>
                <name>hbase.zookeeper.property.dataDir</name>
                <value>/var/hbase/data</value>
        </property>
		说明：该参数为zk的property数据目录
        <property>
                <name>hbase.tmp.dir</name>
                <value>/var/hbase/tmp</value>
        </property>
		说明：该参数为hbase的临时目录
        <property>
                <name>hbase.local.dir</name>
                <value>/var/hbase/local</value>
 		</property>
		说明：该参数为hbase的local目录
3. backup-masters
	该配置文件中的内容为hbase备节点，格式如下：
	node02
4. regionservers
	该配置文件中的内容为hbase的regionserver节点，内容格式与slaves文件一致，	默认情况下，内容也与slaves文件一致。
5. metaRegion
	该配置文件需要由研发给出。
6. hdfs-site.xml
	该配置文件与$HADOOP_HOME/etc/hadoop/hdfs-site.xml一致

Zookeeper：配置文件所在目录为$ZK_HOME/conf，需要配置的配置文件有java.env、	zoo.cfg。
1. java.env
	需要配置以下参数，其余参数采用默认值。
	JAVA_HOME、	JVMFLAGS，其中JAVA_HOME为java的安装目录，JVMFLAGS为jvm的参数，采用默认值即可。
2. zoo.cfg
	需要配置以下参数，其余参数采用默认值。
	dataDir、dataLogDir分别为数据目录、日志目录。
	zk节点，格式如下：
	server.1=loc1-meta03:2888:3888
	server.2=loc2-meta01:2888:3888
	server.3=loc2-meta02:2888:3888
	server.4=loc3-meta01:2888:3888
	server.5=loc3-meta02:2888:3888
3.修改zk日志存放目录
      配置log4j.properties文件中zookeeper.root.logger=INFO,ROLLINGFILE
	  配置zkEnv.sh文件中ZOO_LOG_DIR="/data1/logs/zookeeper"

三、 运行
启动顺序为zookeeper、hadoop、hbase，具体启动如下：
Zookeeper：
	首先，在各个zk节点上创建dataDir、dataLogDir目录，然后分别在dataDir目录下创建文件myid，并依此写入1、2、3.。。，比如第一个zk节点的myid文件写入1，则第二个写入2.。。
	其次，在各个zk节点上运行zkServer.sh start，所有zk节点上的zk进程启动之后，可运行zkServer.sh status查看各个zk节点的状态，只有一个是leader，其余的都是follower。
	重启：zkServer.sh restart
	停止：zkServer.sh stop
在启动Hadoop、HBase之前，首先执行hbase dispatcher start(本指命分发metaRegion配置，只有在metaRegion配置发生变化时分发，具体什么时候执行由研发定)
Hadoop：需要启动以下进程NameNode、DataNode、JournalNode。
	1、依次在各节点上启动qjournal，启动方法为hadoop-daemon.sh start journalnode
2、在两个NN节点上启动zkfc，启动方法为hadoop-daemon.sh start zkfc(zkfc和两个NN启动顺序无要求)
*hadoop-daemon.sh start|stop  namenode|secondarynamenode|datanode|journalnode|dfs|dfsadmin|fsck|balancer|zkfc 命令可以手动重启各服务。
	3、在主节点上，运行hdfs zkfc -formatZK
 

	在主节点上运行hdfs namenode -format进行格式化，然后将主节点的${ hadoop.tmp.dir }目录拷贝到备节点的相同目录下
	启动hdfs，start-dfs.sh
	启动之后可通过：hdfs dfsadmin -report查看集群的状态
	停止：stop-dfs.sh
*服务启动后日志存放于/data1/logs/hdfs/*

HBase：
	首先启动FailoverTracker(只要一个主节点启动即hmaster)：
nohup hbase failoverTracker &
	启动：start-hbase.sh
	停止：stop-hbase.sh
